{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize OK\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('lab10.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Lab 10: Logistic Regression \n",
    "\n",
    "**Collaboration Policy**\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about\n",
    "the homework, we ask that you **write your solutions individually**. If you do\n",
    "discuss the assignments with others please **include their names** at the top\n",
    "of your solution.\n",
    "\n",
    "## Due Date\n",
    "\n",
    "This assignment is due at 11:59pm Tuesday, July 30th.\n",
    "\n",
    "In this lab you will fit a logistic regression model and evaluate using a few metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborators  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write names in this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "setup",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "dataset",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "In this lab we will be working on the breast cancer dataset. This dataset can be easily loaded using the `sklearn.datasets.load_breast_cancer()` method. The data format is not a `pandas.DataFrame` so we will create a new DataFrame from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "loaddata",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = sklearn.datasets.load_breast_cancer()\n",
    "# data is actually a dictionnary\n",
    "print(data.keys())\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "dataframe",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "fitone",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Let us try to fit a simple model with only one feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "buildxy",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Define our features/target\n",
    "X = df[[\"mean radius\"]]\n",
    "# Target data['target'] = 0 is malignant 1 is benign\n",
    "Y = (data.target == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "split",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Split between train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test,y_train,y_test = train_test_split(X,Y, test_size=0.25, random_state=42)\n",
    "\n",
    "print(f\"Training Data Size: {len(x_train)}\")\n",
    "print(f\"Test Data Size: {len(x_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q1_text",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1\n",
    "\n",
    "Let's first fit a logistic regression model using the training set. We will compute the training and testing accuracy, defined as:\n",
    "\n",
    "$$\n",
    "\\large\n",
    "\\text{Training Accuracy} = \\frac{1}{n_{train\\_set}} \\sum_{i \\in \\text{train_set}} {\\mathbb{1}_{y_i == \\hat{y_i}}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\large\n",
    "\\text{Testing Accuracy} = \\frac{1}{n_{test\\_set}} \\sum_{i \\in \\text{test_set}} {\\mathbb{1}_{y_i == \\hat{y_i}}}\n",
    "$$\n",
    "\n",
    "where $\\hat y_i $ is the prediction of our model, $ y_i $ the true value, and $\\mathbb{1}_{y_i == \\hat{y_i}}$ an indicator function ($ \\mathbb{1}_{y_i == \\hat{y_i}} = 1 $ if and only if  $ y_i = \\hat{y_i}$).\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1_code",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "lr = sklearn.linear_model.LogisticRegression(fit_intercept=True)\n",
    "\n",
    "...\n",
    "train_accuracy = ...\n",
    "test_accuracy = ...\n",
    "\n",
    "print(f\"Train accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_text",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 2\n",
    "It seems we can a get very high test accuracy. Then how about precision and recall?  \n",
    "- Precision is the fraction of instances you predicted as 1 that were actually 1.  \n",
    "- Recall is the fraction of instances are actually 1 that you predicted as 1.\n",
    "\n",
    "Precision measures the ability of the classifier not to label as positive a sample that is negative, while recall measures the ability of the classifier to find all the positive samples.\n",
    "\n",
    "A **confusion matrix** helps us visualize/calculate the precision and recall of a classifier. Below, we compute the confusion matrix for our classifier.\n",
    "\n",
    "We also compute the normalized confusion matrix, which is the same as the confusion matrix, but the numbers are converted to percents (sometimes it's easier to interpret percents as opposed to numbers, especially when the numbers are really big or small)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_display",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, lr.predict(x_test))\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "class_names = ['False', 'True']\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_text2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Mathematically:\n",
    "$$\n",
    "\\text{Precision} = \\frac{n_{true\\_positives}}{n_{true\\_positives} + n_{false\\_positives}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{n_{true\\_positives}}{n_{true\\_positives} + n_{false\\_negatives}}\n",
    "$$\n",
    "\n",
    "As illustrated in the figure below:\n",
    "![precision_recall](precision_recall.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-sd",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Now let's compute the precision and recall for the test set using the model we got from question 1.  \n",
    "Please do not use the `sklearn.metrics` for this computation. Instead, use the formulas above.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_code",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred = lr.predict(x_test) \n",
    "\n",
    "precision = ...\n",
    "recall = ...\n",
    "\n",
    "print(f'precision = {precision:.4f}')\n",
    "print(f'recall = {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_question",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "What can you infer from these results? Please consider the following plots, that display the distribution of the target variable in the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_display2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "sns.countplot(y_train, ax=axes[0]);\n",
    "sns.countplot(y_test, ax=axes[1]);\n",
    "\n",
    "axes[0].set_title('Train')\n",
    "axes[1].set_title('Test')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3_text",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "###  Question 3\n",
    "Now let's try to analyze the cross entropy loss. Recall that loss would be:\n",
    "$$\\Large L(\\theta) = -\\frac{1}{n} \\sum_{i=1}^n \\left( y_i \\log(z_i) + (1 - y_i) \\log(1 - z_i)  \\right) $$\n",
    "\n",
    "where $z_i = \\sigma(\\theta \\cdot X_i)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3_setup",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "theta = np.array([lr.coef_[0][0],\n",
    "                  lr.intercept_[0]])\n",
    "X_new = np.hstack([X,\n",
    "                 np.ones([len(X), 1])]) # This is adding a coefficient of 1 for the intercept term\n",
    "print(theta)\n",
    "print()\n",
    "print(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the function `lr_loss` which computes the cross-entropy loss. Note that you have been given `sigmoid`, which implements the $\\sigma$ function for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3_code",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    return 1 / (1 + np.exp(-t))\n",
    "def lr_loss(theta, X, Y):\n",
    "    '''\n",
    "    Compute the cross entropy loss using Phi, Y and theta. Hint: # The notation B @ v means: \n",
    "    compute the matrix multiplication Bv \n",
    "\n",
    "    Args:\n",
    "        theta: The model parameters. \n",
    "        Phi: The transformed input data \\phi(X)\n",
    "        Y: The label \n",
    "\n",
    "    Return:\n",
    "        The cross entropy loss.\n",
    "    '''\n",
    "    loss = ...\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q3\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You're done! Make sure to submit to okpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Submit\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output.\n",
    "**Please save before submitting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to submit.\n",
    "ok.submit()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
