{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import warnings\n",
    "# Ignore numpy dtype warnings. These warnings are caused by an interaction\n",
    "# between numpy and Cython and can be safely ignored.\n",
    "# Reference: https://stackoverflow.com/a/40846742\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import nbinteract as nbi\n",
    "\n",
    "sns.set()\n",
    "sns.set_context('talk')\n",
    "np.set_printoptions(threshold=20, precision=2, suppress=True)\n",
    "pd.set_option('display.max_rows', 7)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "pd.set_option('precision', 2)\n",
    "# This option stops scientific notation for pandas\n",
    "# pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "def df_interact(df, nrows=7, ncols=7):\n",
    "    '''\n",
    "    Outputs sliders that show rows and columns of df\n",
    "    '''\n",
    "    def peek(row=0, col=0):\n",
    "        return df.iloc[row:row + nrows, col:col + ncols]\n",
    "\n",
    "    row_arg = (0, len(df), nrows) if len(df) > nrows else fixed(0)\n",
    "    col_arg = ((0, len(df.columns), ncols)\n",
    "               if len(df.columns) > ncols else fixed(0))\n",
    "    \n",
    "    interact(peek, row=row_arg, col=col_arg)\n",
    "    print('({} rows, {} columns) total'.format(df.shape[0], df.shape[1]))\n",
    "\n",
    "def display_df(df, rows=pd.options.display.max_rows,\n",
    "               cols=pd.options.display.max_columns):\n",
    "    with pd.option_context('display.max_rows', rows,\n",
    "                           'display.max_columns', cols):\n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized Logistic Regression\n",
    "\n",
    "As with linear regression, one common way of reducing the variance of the parameter estimator is to add a regularization term to the empirical risk objective. E.g.,\n",
    "\n",
    "\\begin{align*}\n",
    "R(\\beta, x, y, \\lambda) &= - \\frac{1}{n}\\sum_{i=1}^n \\left[ y_i x_i^T\\beta + \\log \\sigma(-x_i^T\\beta) \\right] + \\frac{1}{2} C \\sum_{j=1}^J \\beta_j^2 \\\\[10pt]\n",
    "\\nabla_{\\beta} R(\\beta, x, y, \\lambda) &=  - \\frac{1}{n}\\sum_{i=1}^n \\left(y_i - \\sigma(x_i^T\\beta)\\right) x_i + C \\beta \\\\[10pt]\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c = 0.0009765625\n",
      "sum(beta**2) =  181.05862166469308\n",
      "Train: 406/426 (95.3%)\n",
      "Test: 137/143 (95.8%)\n",
      "\n",
      "c = 0.00390625\n",
      "sum(beta**2) =  153.17656348299207\n",
      "Train: 406/426 (95.3%)\n",
      "Test: 137/143 (95.8%)\n",
      "\n",
      "c = 0.015625\n",
      "sum(beta**2) =  84.76727676186307\n",
      "Train: 401/426 (94.1%)\n",
      "Test: 139/143 (97.2%)\n",
      "\n",
      "c = 0.0625\n",
      "sum(beta**2) =  16.86808437919907\n",
      "Train: 396/426 (93.0%)\n",
      "Test: 137/143 (95.8%)\n",
      "\n",
      "c = 0.25\n",
      "sum(beta**2) =  1.159763781457247\n",
      "Train: 392/426 (92.0%)\n",
      "Test: 135/143 (94.4%)\n",
      "\n",
      "c = 1.0\n",
      "sum(beta**2) =  0.21983095016705734\n",
      "Train: 390/426 (91.5%)\n",
      "Test: 134/143 (93.7%)\n",
      "\n",
      "c = 4.0\n",
      "sum(beta**2) =  0.08526863018405177\n",
      "Train: 390/426 (91.5%)\n",
      "Test: 134/143 (93.7%)\n",
      "\n",
      "c = 16.0\n",
      "sum(beta**2) =  0.06240644243334323\n",
      "Train: 390/426 (91.5%)\n",
      "Test: 134/143 (93.7%)\n",
      "\n",
      "c = 64.0\n",
      "sum(beta**2) =  0.043885815938907356\n",
      "Train: 388/426 (91.1%)\n",
      "Test: 134/143 (93.7%)\n",
      "\n",
      "c = 256.0\n",
      "sum(beta**2) =  0.016109390288629684\n",
      "Train: 387/426 (90.8%)\n",
      "Test: 136/143 (95.1%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def regularized_logistic_regression(x, y, c):\n",
    "    \"\"\"Train a logistic regression classifier using gradient descent.\"\"\"\n",
    "\n",
    "    def l2_regularized_gradient(beta, x, y):\n",
    "        return risk_gradient(beta, x, y) + c * beta\n",
    "\n",
    "    beta0 = np.zeros(x.shape[0])\n",
    "    beta = gradient_descent(x, y, beta0, l2_regularized_gradient)\n",
    "    return beta    \n",
    "\n",
    "def search_for_c(features):\n",
    "    for c in 2.0 ** np.arange(-10, 10, 2):\n",
    "        print(\"c =\", c)\n",
    "        beta = regularized_logistic_regression(features(train), y_train, c)\n",
    "        print(\"sum(beta**2) = \", sum(beta**2))\n",
    "        evaluate(beta, features)\n",
    "        print()\n",
    "        \n",
    "search_for_c(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c = 0.0009765625\n",
      "sum(beta**2) =  35.8486017048037\n",
      "Train: 423/426 (99.3%)\n",
      "Test: 138/143 (96.5%)\n",
      "\n",
      "c = 0.00390625\n",
      "sum(beta**2) =  31.318273815172542\n",
      "Train: 423/426 (99.3%)\n",
      "Test: 138/143 (96.5%)\n",
      "\n",
      "c = 0.015625\n",
      "sum(beta**2) =  20.747956964144077\n",
      "Train: 423/426 (99.3%)\n",
      "Test: 139/143 (97.2%)\n",
      "\n",
      "c = 0.0625\n",
      "sum(beta**2) =  9.935156093274612\n",
      "Train: 421/426 (98.8%)\n",
      "Test: 141/143 (98.6%)\n",
      "\n",
      "c = 0.25\n",
      "sum(beta**2) =  4.279626098449614\n",
      "Train: 419/426 (98.4%)\n",
      "Test: 141/143 (98.6%)\n",
      "\n",
      "c = 1.0\n",
      "sum(beta**2) =  1.717220435886093\n",
      "Train: 414/426 (97.2%)\n",
      "Test: 140/143 (97.9%)\n",
      "\n",
      "c = 4.0\n",
      "sum(beta**2) =  0.6094833404635616\n",
      "Train: 412/426 (96.7%)\n",
      "Test: 139/143 (97.2%)\n",
      "\n",
      "c = 16.0\n",
      "sum(beta**2) =  0.17553643009069883\n",
      "Train: 405/426 (95.1%)\n",
      "Test: 138/143 (96.5%)\n",
      "\n",
      "c = 64.0\n",
      "sum(beta**2) =  0.03500234439319296\n",
      "Train: 403/426 (94.6%)\n",
      "Test: 136/143 (95.1%)\n",
      "\n",
      "c = 256.0\n",
      "sum(beta**2) =  0.0041317425176505785\n",
      "Train: 399/426 (93.7%)\n",
      "Test: 134/143 (93.7%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def inputs(t):\n",
    "    return t.drop('malignant', axis=1).values\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(inputs(train))\n",
    "\n",
    "def scaled_features(t):\n",
    "    return scaler.transform(inputs(t)).T\n",
    "\n",
    "search_for_c(scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/143 (96.5%)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=4, solver='lbfgs')\n",
    "model.fit(scaled_features(train).T, y_train)\n",
    "y_hat = model.predict(scaled_features(test).T)\n",
    "print_ratio(sum(y_hat == y_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass classification\n",
    "\n",
    "\\begin{align*}\n",
    "P(Y=y|X) &= \\frac{\\exp(X^T\\beta_{y})}{\\sum_{z=0}^d \\exp(X^T\\beta_z)} \\\\[10pt]\n",
    "L(\\beta_0,\\dots,\\beta_d, x_i, y_i) &= - \\log \\frac{\\exp(x_i^T\\beta_{y_i})}{\\sum_{z=0}^d \\exp(x_i^T\\beta_z)} \\\\[10pt]\n",
    "\\frac{\\partial}{\\partial \\beta_w} L(\\beta_0,\\dots,\\beta_d, x_i, y_i) &= -\\left(1[w=y_i] - \\frac{\\exp(x_i^T\\beta_w)}{\\sum_{z=0}^d \\exp(x_i^T\\beta_z)}\\right) x_i  \\\\[10pt]\n",
    "1[w=y_i] &= \\begin{cases}\n",
    "1 & \\text{if}\\ w=y_i \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)  \n",
       "count        150.000000  \n",
       "mean           1.199333  \n",
       "std            0.762238  \n",
       "min            0.100000  \n",
       "25%            0.300000  \n",
       "50%            1.300000  \n",
       "75%            1.800000  \n",
       "max            2.500000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = sklearn.datasets.load_iris()\n",
    "x = pd.DataFrame(data_dict['data'], columns=data_dict['feature_names'])\n",
    "y = data_dict['target']\n",
    "x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([50, 50, 50]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
