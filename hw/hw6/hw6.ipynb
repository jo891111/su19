{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize OK\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('hw6.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6: Predicting Housing Prices (Continued)\n",
    "\n",
    "## Due Date: 11:59 PM Tuesday, July 30\n",
    "\n",
    "### Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the homework, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** in the collaborators cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators:** *write names here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This assignment will continue from where we left off in in Homework 5. Recall that the linear model that you created failed to produce accurate estimates of the observed housing prices because the model was too simple. The goal of this homework is to guide you through the iterative process of specifying, fitting, and analyzing the performance of more complex linear models used to predict prices of houses in Ames, Iowa. Additionally, you will have the opportunity to choose your own features and create your own regression model!\n",
    "\n",
    "By the end of this homework, you should feel comfortable:\n",
    "\n",
    "1. Identifying informative variables through EDA\n",
    "2. Feature engineering categorical variables\n",
    "3. Using sklearn to build more complex linear models\n",
    "\n",
    "## Score Breakdown\n",
    "\n",
    "Question | Points\n",
    "--- | ---\n",
    "[Question 1a](#q1a) | 1\n",
    "[Question 1b](#q1b) | 1\n",
    "[Question 1c](#q1c) | 1\n",
    "[Question 2a](#q2a) | 1\n",
    "[Question 2b](#q2b) | 2\n",
    "[Question 3a](#q3a) | 1\n",
    "[Question 3b](#q3b) | 2\n",
    "[Question 3c](#q3c) | 1\n",
    "[Question 3d](#q3d) | 2\n",
    "[Question 4](#q4) | 6\n",
    "[Question 5a](#q5a) | 2\n",
    "[Question 5b](#q5b) | 2\n",
    "Total | 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data\n",
    "\n",
    "As a reminder, the [Ames dataset](http://jse.amstat.org/v19n3/decock.pdf) consists of 2930 records taken from the Ames, Iowa, Assessorâ€™s Office describing houses sold in Ames from 2006 to 2010.  The data set has 23 nominal, 23 ordinal, 14 discrete, and 20 continuous variables (and 2 additional observation identifiers) --- 82 features in total.  An explanation of each variable can be found in the included `codebook.txt` file.  The information was used in computing assessed values for individual residential properties sold in Ames, Iowa from 2006 to 2010.\n",
    "\n",
    "The raw data are split into training and test sets with 2000 and 930 observations, respectively. To save some time, we've used a slightly modified data cleaning pipeline from last week's assignment to prepare the training data. This data is stored in `ames_train_cleaned.csv`. It consists of 1998 observations and 83 features (we added TotalBathrooms from Homework 5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"ames_train_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV: More Feature Selection and Engineering\n",
    "\n",
    "In this section, we identify two more features of the dataset that will increase our linear regression model's accuracy. Additionally, we will implement one-hot encoding so that we can include binary and categorical variables in our improved model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Neighborhood vs Sale Price\n",
    "\n",
    "First, let's take a look at the relationship between neighborhood and sale prices of the houses in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2)\n",
    "\n",
    "sns.boxplot(\n",
    "    x='Neighborhood',\n",
    "    y='SalePrice',\n",
    "    data=training_data.sort_values('Neighborhood'),\n",
    "    ax=axs[0]\n",
    ")\n",
    "\n",
    "sns.countplot(\n",
    "    x='Neighborhood',\n",
    "    data=training_data.sort_values('Neighborhood'),\n",
    "    ax=axs[1]\n",
    ")\n",
    "\n",
    "# Draw median price\n",
    "axs[0].axhline(\n",
    "    y=training_data['SalePrice'].median(), \n",
    "    color='red',\n",
    "    linestyle='dotted'\n",
    ")\n",
    "\n",
    "# Label the bars with counts\n",
    "for patch in axs[1].patches:\n",
    "    x = patch.get_bbox().get_points()[:, 0]\n",
    "    y = patch.get_bbox().get_points()[1, 1]\n",
    "    axs[1].annotate(f'{int(y)}', (x.mean(), y), ha='center', va='bottom')\n",
    "    \n",
    "# Format x-axes\n",
    "axs[1].set_xticklabels(axs[1].xaxis.get_majorticklabels(), rotation=90)\n",
    "axs[0].xaxis.set_visible(False)\n",
    "\n",
    "# Narrow the gap between the plots\n",
    "plt.subplots_adjust(hspace=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1a <a name=\"q1a\"></a> \n",
    "\n",
    "Based on the plot above, what can be said about the relationship between the houses' sale prices and their neighborhoods?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "points: 1\n",
    "manual: True\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1b <a name=\"q1b\"></a> \n",
    "\n",
    "One way we can deal with the lack of data from some neighborhoods is to create a new feature that bins neighborhoods together.  Let's categorize our neighborhoods in a crude way: we'll take the top 3 neighborhoods measured by median `SalePrice` and identify them as \"rich neighborhoods\"; the other neighborhoods are not marked.\n",
    "\n",
    "Write a function that returns list of the top n most pricy neighborhoods as measured by our choice of aggregating function.  For example, in the setup above, we would want to call `find_rich_neighborhoods(training_data, 3, np.median)` to find the top 3 neighborhoods measured by median `SalePrice`.\n",
    "\n",
    "*The provided tests check that you answered correctly, so that future analyses are not corrupted by a mistake.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rich_neighborhoods(data, n=3, metric=np.median):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): should contain at least a string-valued Neighborhood\n",
    "        and a numeric SalePrice column\n",
    "      n (int): the number of top values desired\n",
    "      metric (function): function used for aggregating the data in each neighborhood.\n",
    "        for example, np.median for median prices\n",
    "    \n",
    "    Output:\n",
    "      a list of the top n richest neighborhoods as measured by the metric function\n",
    "    \"\"\"\n",
    "    neighborhoods = ...\n",
    "    return neighborhoods\n",
    "\n",
    "rich_neighborhoods = find_rich_neighborhoods(training_data, 3, np.median)\n",
    "rich_neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1c <a name=\"q1c\"></a> \n",
    "\n",
    "We now have a list of neighborhoods we've deemed as richer than others.  Let's use that information to make a new variable `in_rich_neighborhood`.  Write a function `add_rich_neighborhood` that adds an indicator variable which takes on the value 1 if the house is part of `rich_neighborhoods` and the value 0 otherwise.\n",
    "\n",
    "**Hint:** [`pd.Series.astype`](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.Series.astype.html) may be useful for converting True/False values to integers.\n",
    "\n",
    "*The provided tests check that you answered correctly, so that future analyses are not corrupted by a mistake.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1c\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_in_rich_neighborhood(data, neighborhoods):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): a data frame containing a 'Neighborhood' column with values\n",
    "        found in the codebook\n",
    "      neighborhoods (list of strings): strings should be the names of neighborhoods\n",
    "        pre-identified as rich\n",
    "    Output:\n",
    "      data frame identical to the input with the addition of a binary\n",
    "      in_rich_neighborhood column\n",
    "    \"\"\"\n",
    "    data['in_rich_neighborhood'] = ...\n",
    "    return data\n",
    "\n",
    "rich_neighborhoods = find_rich_neighborhoods(training_data, 3, np.median)\n",
    "training_data = add_in_rich_neighborhood(training_data, rich_neighborhoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1c\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 2: Fireplace Quality\n",
    "\n",
    "In the following question, we will take a closer look at the Fireplace_Qu feature of the dataset and examine how we can incorporate categorical features into our linear model.\n",
    "\n",
    "### Question 2a <a name=\"q2a\"></a>\n",
    "\n",
    "Let's see if our data set has any missing values.  Create a Series object containing the counts of missing values in each of the columns of our data set, sorted from greatest to least.  The Series should be indexed by the variable names.  For example, `missing_counts['Fireplace_Qu']` should return 975.\n",
    "\n",
    "**Hint:** [`pandas.DataFrame.isnull`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isnull.html) may help here.\n",
    "\n",
    "*The provided tests check that you answered correctly, so that future analyses are not corrupted by a mistake.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_counts = ...\n",
    "missing_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q2a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that if we look at the codebook carefully, some of these \"missing values\" aren't missing at all! The Assessor's Office just used `NA` to denote a special value or that the information was truly not applicable for one reason or another.  One such example is the `Fireplace_Qu` variable.\n",
    "```\n",
    "FireplaceQu (Ordinal): Fireplace quality\n",
    "\n",
    "       Ex\tExcellent - Exceptional Masonry Fireplace\n",
    "       Gd\tGood - Masonry Fireplace in main level\n",
    "       TA\tAverage - Prefabricated Fireplace in main living area or Masonry Fireplace inbasement\n",
    "       Fa\tFair - Prefabricated Fireplace in basement\n",
    "       Po\tPoor - Ben Franklin Stove\n",
    "       NA\tNo Fireplace\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2b <a name=\"q2b\"></a>\n",
    "\n",
    "An `NA` here actually means that the house had no fireplace to rate.  Let's fix this in our data set.  Write a function that replaces the missing values in `Fireplace_Qu` with `'No Fireplace'`.  In addition, it should replace each abbreviated condition with its full word.  For example, `'TA'` should be changed to `'Average'`.  Hint: the [DataFrame.replace](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.replace.html) method may be useful here.\n",
    "\n",
    "*The provided tests check that part of your answer is correct, but they are not fully comprehensive.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2b\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_fireplace_qu(data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): a data frame containing a Fireplace_Qu column.  Its values\n",
    "                         should be limited to those found in the codebook\n",
    "    Output:\n",
    "      data frame identical to the input except with a refactored Fireplace_Qu column\n",
    "    \"\"\"\n",
    "    ...\n",
    "    return data\n",
    "    \n",
    "training_data = fix_fireplace_qu(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q2b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Important Note on One Hot Encoding <a name=\"important_note\"></a>\n",
    "\n",
    "Unfortunately, simply fixing these missing values isn't sufficient for using `Fireplace_Qu` in our model.  Since `Fireplace_Qu` is a categorical variable, we will have to one-hot-encode the data.  Notice in the example code below that we have to pre-specify the categories.  Why? Imagine what would happen if we automatically generated the categories only from the training data.  What would happen if the testing data contained a category not found in the training set?  For more information on categorical data in pandas, refer to this [link](https://pandas-docs.github.io/pandas-docs-travis/categorical.html).  **Note that `get_dummies` removes the original column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe_fireplace_qu(data):\n",
    "    \"\"\"\n",
    "    One-hot-encodes fireplace quality.  New columns are of the form fpq_QUALITY\n",
    "    \"\"\"\n",
    "    cats = [\n",
    "        'Excellent',\n",
    "        'Good',\n",
    "        'Average',\n",
    "        'Fair',\n",
    "        'Poor',\n",
    "        'No Fireplace'\n",
    "    ]\n",
    "    \n",
    "    cat_type = CategoricalDtype(categories=cats)\n",
    "    \n",
    "    data.loc[:, 'Fireplace_Qu'] = data.loc[:, 'Fireplace_Qu'].astype(cat_type)\n",
    "    data = pd.get_dummies(data,\n",
    "                          prefix='fpq',\n",
    "                          columns=['Fireplace_Qu'], \n",
    "                          drop_first=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = ohe_fireplace_qu(training_data)\n",
    "training_data.filter(regex='fpq').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part V: Improved Linear Models\n",
    "\n",
    "In this section, we will create linear models that produce more accurate estimates of the housing prices in Ames than the model created in Homework 5, but at the expense of increased complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Adding Covariates to our Model\n",
    "\n",
    "It's finally time to fit our updated linear regression model using the ordinary least squares estimator! Our new model consists of the linear model from Homework 5, with the addition of the our newly created `in_rich_neighborhood` variable and our one-hot-encoded fireplace quality variables:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\text{SalePrice} & = \\theta_0 + \\theta_1 \\cdot \\text{Gr_Liv_Area} + \\theta_2 \\cdot \\text{Garage_Area} + \n",
    "\\theta_3 \\cdot \\text{TotalBathrooms} + \\theta_4 \\cdot \\text{in_rich_neighborhood} + \\\\\n",
    "& \\quad \\: \\theta_5 \\cdot \\text{fpq_Good} + \\theta_6 \\cdot \\text{fpq_Average} + \\theta_7 \\cdot \\text{fpq_Fair} +\n",
    "\\theta_8 \\cdot \\text{fpq_Poor} + \\theta_9 \\cdot \\text{fpq_No_Fireplace}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3a <a name=\"q3a\"></a>\n",
    "\n",
    "Although the firepalce quality variable that we explored in Question 2 has six categories, only five of these categories' indicator variables are inclulded in our model. Is this a mistake, or is it done intentionally? Why?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a\n",
    "points: 1\n",
    "manual: True\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3b <a name=\"q3b\"></a>\n",
    "\n",
    "We still have a little bit of work to do prior to estimating our linear regression model's coefficients. Instead of having you go through the process of splitting our data into training and testing sets, selecting the pertinent convariates and creating a [`sklearn.linear_model.LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) object for our linear model again, we provide the necessary code from Homework 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will re-import the data and split `training_data` into a training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"ames_train_cleaned.csv\")\n",
    "\n",
    "# This makes the train-test split in this section reproducible across different runs \n",
    "# of the notebook. You do not need this line to run train_test_split in general\n",
    "np.random.seed(1337)\n",
    "training_data_len = len(training_data)\n",
    "shuffled_indices = np.random.permutation(training_data_len)\n",
    "\n",
    "# Set train_indices to the first 80% of shuffled_indices and and test_indices to the rest.\n",
    "train_indices = shuffled_indices[:int(training_data_len * 0.8)]\n",
    "test_indices = shuffled_indices[int(training_data_len * 0.8):]\n",
    "\n",
    "# Create train and test` by indexing into `full_data` using \n",
    "# `train_indices` and `test_indices`\n",
    "train = training_data.iloc[train_indices]\n",
    "test = training_data.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will implement a reusable pipeline that selects the required variables in our data and splits our covariates and response variable into a matrix and a vector, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(data, *columns):\n",
    "    \"\"\"Select only columns passed as arguments.\"\"\"\n",
    "    return data.loc[:, columns]\n",
    "\n",
    "def process_data_gm(data):\n",
    "    \"\"\"Process the data for a guided model.\"\"\"\n",
    "    # One-hot-encode fireplace quality feature\n",
    "    data = fix_fireplace_qu(data)\n",
    "    data = ohe_fireplace_qu(data)\n",
    "    \n",
    "    # Use rich_neighborhoods computed earlier to add in_rich_neighborhoods feature\n",
    "    data = add_in_rich_neighborhood(data, rich_neighborhoods)\n",
    "    \n",
    "    # Transform Data, Select Features\n",
    "    data = select_columns(data, \n",
    "                          'SalePrice', \n",
    "                          'Gr_Liv_Area', \n",
    "                          'Garage_Area',\n",
    "                          'TotalBathrooms',\n",
    "                          'in_rich_neighborhood',\n",
    "                          'fpq_Good',\n",
    "                          'fpq_Average',\n",
    "                          'fpq_Fair',\n",
    "                          'fpq_Poor',\n",
    "                          'fpq_No Fireplace',\n",
    "                         )\n",
    "    \n",
    "    # Return predictors and response variables separately\n",
    "    X = data.drop(['SalePrice'], axis = 1)\n",
    "    y = data.loc[:, 'SalePrice']\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then split our dataset into training and testing sets using our data cleaning pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process our training and test data in exactly the same way\n",
    "# Our functions make this very easy!\n",
    "X_train, y_train = process_data_gm(train)\n",
    "X_test, y_test = process_data_gm(test)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we initialize a [`sklearn.linear_model.LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) object as our linear model. We set the `fit_intercept = True` to ensure that the linear model has a non-zero intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model as lm\n",
    "\n",
    "linear_model = lm.LinearRegression(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "After a little bit of work, it's finally time to fit our updated linear regression model. Use the cell below to estimate the model, and then use it to compute the fitted value of `SalePrice` over the training data and the predicted the values of `SalePrice` using the testing data. \n",
    "\n",
    "*The provided tests check that you answered correctly, so that future analyses are not corrupted by a mistake.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3b\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model below\n",
    "\n",
    "# Compute the fitted and predicted values of SalePrice\n",
    "y_fitted = ...\n",
    "y_predicted = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q3b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3c <a name=\"q3c\"></a>\n",
    "\n",
    "Let's assess the performance of our new linear regression model using the Root Mean Squared Error function that we created in Homework 5.\n",
    "\n",
    "$$RMSE = \\sqrt{\\dfrac{\\sum_{\\text{houses in test set}}(\\text{actual price for house} - \\text{predicted price for house})^2}{\\text{# of houses}}}$$\n",
    "\n",
    "The function is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predicted, actual):\n",
    "    \"\"\"\n",
    "    Calculates RMSE from actual and predicted values\n",
    "    Input:\n",
    "      predicted (1D array): vector of predicted/fitted values\n",
    "      actual (1D array): vector of actual values\n",
    "    Output:\n",
    "      a float, the root-mean square error\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean((actual - predicted)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now use your `rmse` function to calculate the training error and test error in the cell below.\n",
    "\n",
    "*The provided tests for this question do not confirm that you have answered correctly; only that you have assigned each variable to a non-negative number.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3c\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_error = ...\n",
    "test_error = ...\n",
    "print(\"Training RMSE: {}\\nTest RMSE: {}\".format(training_error, test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q3c\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3d <a name=\"q3d\"></a>\n",
    "\n",
    "Compare the predictive accuracy of this model to that of the model that you derived in Homework 5. Is the new model a better predictor of housing prices in Ames? If so, are the gains in accuracy significantly larger? Assume that the training and testing sets used to in Homework 5 are identical to the ones used in this homework.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name : q3d\n",
    "points: 2\n",
    "manual: True\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part VI: Open-Response\n",
    "\n",
    "The following part is purposefully left nearly open-ended.  The Ames data in your possession comes from a larger data set.  Your goal is to provide a linear regression model that accurately predicts the prices of the held-out homes, measured by root mean square error. \n",
    "\n",
    "$$RMSE = \\sqrt{\\dfrac{\\sum_{\\text{houses in public test set}}(\\text{actual price for house} - \\text{predicted price for house})^2}{\\text{# of houses}}}$$\n",
    "\n",
    "Perfect prediction of house prices would have a score of 0, so you want your score to be as low as possible!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Scheme\n",
    "\n",
    "Your grade for Question 4 will be based on your training RMSE and test RMSE. The thresholds are as follows:\n",
    "\n",
    "Points | 3 | 2 | 1 | 0\n",
    "--- | --- | --- | --- | ---\n",
    "Training RMSE | Less than 36k | 36k - 38k | 38k - 40k | More than 40k\n",
    "\n",
    "Points | 3 | 2 | 1 | 0\n",
    "--- | --- | --- | --- | ---\n",
    "Test RMSE | Less than 37k | 37k - 40k | 40k - 43k | More than 43k\n",
    "\n",
    "\n",
    "### One Hot Encoding\n",
    "\n",
    "If you choose to include more categorical features in your model, you'll need to one-hot-encode each one. It may be helpful to read more about the arguments to [`pd.get_dummies`](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html), which can actually handle `NaN` values and multiple categorical variables at once.\n",
    "\n",
    "Also, remember that if a categorical variable has a unique value that is present in the training set but not in the test set, one-hot-encoding this variable will result in different outputs for the training and test sets (different numbers of one-hot columns). Watch out for this! Feel free to look back at how we [one-hot-encoded `Fireplace_Qu`](#important_note) and specified the categories beforehand. \n",
    "\n",
    "To generate all possible categories for a categorical variable, we suggest reading through `codebook.txt`, or finding the values programmatically across both the training and test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 4: Your Own Linear Model <a name=\"q4\"></a>\n",
    "\n",
    "Just as in the guided model above, you should encapsulate as much of your workflow into functions as possible. Below, we have initialized `final_model` for you. Your job is to select better features and define your own feature engineering pipeline in `process_data_fm`. \n",
    "\n",
    "To evaluate your model, we will process training data using your `process_data_fm`, fit `final_model` with this training data, and compute the training RMSE. Then, we will process the test data with your `process_data_fm`, use `final_model` to predict sale prices for the test data, and compute the test RMSE. See below for an example of the code we will run to grade your model:\n",
    "\n",
    "```\n",
    "training_data = pd.read_csv('ames_train_cleaned.csv')\n",
    "test_data = pd.read_csv('ames_test_cleaned.csv')\n",
    "\n",
    "X_train, y_train = process_data_fm(training_data)\n",
    "X_test, y_test = process_data_fm(test_data)\n",
    "\n",
    "final_model.fit(X_train, y_train)\n",
    "y_predicted_train = final_model.predict(X_train)\n",
    "y_predicted_test = final_model.predict(X_test)\n",
    "\n",
    "training_rmse = rmse(y_predicted_train, y_train)\n",
    "test_rmse = rmse(y_predicted_test, y_test)\n",
    "```\n",
    "\n",
    "**Note:** It is your duty to make sure that all of your feature engineering and selection happens in `process_data_fm`, and that the function performs as expected without errors. We will **NOT** accept regrade requests that require us to go back and run code that require typo/bug fixes.\n",
    "\n",
    "**Hint:** Some features may have missing values in the test set but not in the training set. Make sure `process_data_fm` handles missing values appropriately for each feature!\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4\n",
    "points: 6\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = lm.LinearRegression(fit_intercept=True) # No need to change this!\n",
    "\n",
    "def process_data_fm(data):\n",
    "    ...\n",
    "    # Return predictors and response variables separately\n",
    "    X = data.drop(['SalePrice'], axis = 1)\n",
    "    y = data.loc[:, 'SalePrice']\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q4\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 5: EDA for Feature Selection\n",
    "\n",
    "In the following question, explain a choice you made in designing your custom linear model in Question 4. First, make a plot to show something interesting about the data. Then explain your findings from the plot, and describe how these findings motivated a change to your model.\n",
    "\n",
    "### Question 5a <a name=\"q5a\"></a>\n",
    "\n",
    "In the cell below, create a visualization that shows something interesting about the dataset.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5a\n",
    "points: 2\n",
    "manual: True\n",
    "format: image\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for visualization goes here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 5b <a name=\"q5b\"></a>\n",
    "\n",
    "Explain any conclusions you draw from the plot above, and describe how these conclusions affected the design of your model. After creating the plot, did you add/remove certain features from your model, or did you perform some other type of feature engineering? How significantly did these changes affect your rmse?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5b\n",
    "points: 2\n",
    "manual: True\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Submit\n",
    "\n",
    "Make sure that if you run Kernel > Restart & Run All, your notebook produces the expected outputs for each cell. Congratulations on finishing the assignment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to submit.\n",
    "import jassign.to_pdf\n",
    "jassign.to_pdf.generate_pdf('hw6.ipynb', 'hw6.pdf')\n",
    "ok.submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
